# TP3 â€“ DÃ©couverte des rÃ©seaux de neurones avec le MLPClassifier

## ğŸ¯ Objectifs
- Comprendre le fonctionnement dâ€™un rÃ©seau de neurones multicouche (**MLP**).
- Manipuler les principaux **hyperparamÃ¨tres** : nombre de neurones, couches, fonctions dâ€™activation, itÃ©rations.
- Observer les effets dâ€™**underfitting**, dâ€™**overfitting** et de **mauvaise convergence**.
- Relier ces phÃ©nomÃ¨nes au **compromis biais / variance**.
- Approfondir lâ€™intuition de la **descente de gradient** Ã  travers la courbe de perte.

DurÃ©e cible : **2h Ã  2h30**  
Plateforme recommandÃ©e : **Google Colab** (Python 3 + scikit-learn)

---

## Ã‰tape 0 â€” PrÃ©paration et exploration des donnÃ©es
Nous allons travailler sur le dataset **Digits** de Scikit-learn..

ğŸ“š **Aide** : documentation officielle de `load_digits`  
https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html

```python
from sklearn.datasets import load_digits
import matplotlib.pyplot as plt

digits = load_digits()
print("Taille du dataset :", digits.data.shape)
print("Nombre de classes :", len(digits.target_names))

# Visualisation rapide de quelques images
for i in range(4):
    plt.subplot(1,4,i+1)
    plt.imshow(digits.images[i], cmap='gray')
    plt.title(f"Label: {digits.target[i]}")
plt.show()
```

**Q1.** Qu'est ce que le dataset digits ? Combien dâ€™images contient le dataset ? Quelle est la taille de chaque image ?  

**Q2.** Pourquoi les images doivent-elles Ãªtre **aplaties** (converties en 64 colonnes) avant dâ€™Ãªtre utilisÃ©es par un MLP ?  

**Q3.** Combien de classes diffÃ©rentes contient ce jeu de donnÃ©es ?

---

## Ã‰tape 1 â€” CrÃ©er et entraÃ®ner un premier rÃ©seau simple

ğŸ“š **Aide** : documentation `MLPClassifier`  
https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html

Nous allons crÃ©er un rÃ©seau de neurones **avec une seule couche cachÃ©e** contenant 30 neurones.

```python
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay

# Division du dataset en train/test
X_train, X_test, y_train, y_test = train_test_split(
    digits.data, digits.target, test_size=0.3, random_state=42, stratify=digits.target
)

# TODO : ComplÃ©tez les paramÃ¨tres du MLP
mlp = MLPClassifier(hidden_layer_sizes=(...), activation='...', max_iter=200, random_state=42)
mlp.fit(X_train, y_train)

# TODO : prÃ©disez sur le jeu de test
y_pred = mlp.predict(...)

print("Accuracy (train):", mlp.score(..., ...))
print("Accuracy (test):", accuracy_score(..., ...))

ConfusionMatrixDisplay.from_estimator(mlp, X_test, y_test)
plt.show()
```

**Q4.** Quelle est la prÃ©cision obtenue sur le jeu dâ€™entraÃ®nement et de test ?  
**Q5.** Que remarquez-vous dans la matrice de confusion ? Y a-t-il des chiffres plus difficiles Ã  reconnaÃ®tre ?  
**Q6.** Le modÃ¨le semble-t-il sous-apprendre ou sur-apprendre ? Pourquoi ?

---

## Ã‰tape 2 â€” Influence du nombre de neurones et de couches

Nous allons tester plusieurs architectures :  
- Une seule couche cachÃ©e avec 20, 50 et 100 neurones.  
- Puis un rÃ©seau **Ã  deux couches** avec 50 et 20 neurones.

ğŸ’¡ **Indice** : regardez le paramÃ¨tre `hidden_layer_sizes` dans la doc de `MLPClassifier`.

```python
hidden_layers = [(20,), (50,), (100,), (50,20)]
results = []

for hl in hidden_layers:
    # TODO : crÃ©ez le modÃ¨le et entraÃ®nez-le
    model = MLPClassifier(hidden_layer_sizes=hl, activation='relu', max_iter=300, random_state=42)
    model.fit(..., ...)
    acc_train = model.score(..., ...)
    acc_test = model.score(..., ...)
    results.append((hl, acc_train, acc_test))
    print(f"{hl} -> train={acc_train:.3f}, test={acc_test:.3f}")
```

**Q7.** Quelle architecture donne les meilleurs rÃ©sultats sur le test ?  
**Q8.** Pour les architectures avec une seule couche, que se passe-t-il quand on augmente le nombre de neurones ?  
**Q9.** Le rÃ©seau Ã  deux couches fait-il toujours mieux ? Expliquez pourquoi.  
**Q10.** Que pouvez-vous en conclure sur le lien entre **taille du modÃ¨le** et **gÃ©nÃ©ralisation** ?

---

## Ã‰tape 3 â€” Influence de la fonction dâ€™activation

Nous allons comparer trois fonctions dâ€™activation : `relu`, `tanh` et `logistic`.

ğŸ“š **Aide** : paramÃ¨tres `activation` dans la doc de `MLPClassifier`.

```python
activations = ['relu', 'tanh', 'logistic']

# TODO : complÃ©tez la boucle pour entraÃ®ner et Ã©valuer chaque activation
for act in activations:
    model = MLPClassifier(hidden_layer_sizes=(50,20), activation=..., max_iter=300, random_state=42)
    model.fit(..., ...)
    print(f"Activation={act} -> train={model.score(..., ...):.3f}, test={model.score(..., ...):.3f}")
```

**Q11.** Quelle fonction dâ€™activation obtient les meilleurs rÃ©sultats ?  
**Q12.** Quâ€™observez-vous en termes de temps dâ€™entraÃ®nement et de convergence ?  
**Q13.** Pourquoi `ReLU` est-elle souvent privilÃ©giÃ©e dans les rÃ©seaux modernes ?

---

## Ã‰tape 4 â€” Nombre dâ€™itÃ©rations et descente de gradient

Le paramÃ¨tre `max_iter` contrÃ´le le nombre dâ€™itÃ©rations de lâ€™algorithme dâ€™optimisation (descente de gradient).  
Un message dâ€™avertissement â€œ**Maximum iterations reached**â€ indique que le modÃ¨le nâ€™a pas complÃ¨tement convergÃ©.

ğŸ“š **Aide** : consultez `mlp.loss_curve_` pour tracer la courbe dâ€™Ã©volution de lâ€™erreur.

```python
mlp_iter = MLPClassifier(hidden_layer_sizes=(50,20), activation='relu', max_iter=30, random_state=42)
mlp_iter.fit(X_train, y_train)

# TODO : tracez la courbe de la loss
plt.plot(...)
plt.title("Courbe de perte (loss) au fil des itÃ©rations")
plt.xlabel("ItÃ©rations")
plt.ylabel("Loss")
plt.show()
```

**Q14.** Que reprÃ©sente la â€œlossâ€ sur cette courbe ?  
**Q15.** Que se passe-t-il si vous augmentez `max_iter` Ã  200 ou 500 ?  
**Q16.** Que peut-on relier ici Ã  la notion de **descente de gradient** vue en cours ?  
**Q17.** Pourquoi un nombre dâ€™itÃ©rations trop Ã©levÃ© peut-il conduire Ã  un sur-apprentissage ?

---

## Ã‰tape 5 â€” SynthÃ¨se

**Q18.** RÃ©sumez ce que vous avez observÃ© :  
- effet du nombre de neurones,  
- effet du nombre de couches,  
- effet de la fonction dâ€™activation,  
- effet du nombre dâ€™itÃ©rations.  

**Q19.** Comment ces observations sâ€™inscrivent-elles dans le compromis **biais / variance** ?  
**Q20.** Quelle combinaison dâ€™hyperparamÃ¨tres vous semble la plus Ã©quilibrÃ©e pour ce dataset ?  

---

## ğŸš€ Pour aller plus loin (optionnel)

1. **Tester un rÃ©seau plus profond** : ajoutez une troisiÃ¨me couche cachÃ©e, par exemple `(100, 50, 20)`.  
   Observez les effets sur la prÃ©cision et le temps dâ€™entraÃ®nement.  
2. **Comparer avec un modÃ¨le plus simple** : entraÃ®nez une rÃ©gression logistique sur le mÃªme dataset (`LogisticRegression`).  
   Comparez les performances avec celles du MLP.  
3. **Visualiser les erreurs** : affichez quelques chiffres mal classÃ©s pour comprendre les confusions du modÃ¨le.

```python
import numpy as np
# TODO : complÃ©tez le code pour afficher 4 erreurs de prÃ©diction
misclassified = np.where(... != ...)[0][:4]
for idx in misclassified:
    plt.imshow(...[idx].reshape(8,8), cmap='gray')
    plt.title(f"Vrai: {...[idx]} / PrÃ©dit: {...[idx]}")
    plt.show()
```

> ğŸ’¬ Ces explorations vous permettront de mieux comprendre la capacitÃ© des rÃ©seaux de neurones Ã  apprendre des reprÃ©sentations non linÃ©aires, mais aussi leurs limites quand la complexitÃ© est trop Ã©levÃ©e ou mal rÃ©glÃ©e.
