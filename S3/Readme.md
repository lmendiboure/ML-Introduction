# TP3 ‚Äì D√©couverte des r√©seaux de neurones avec le MLPClassifier

## Objectifs
- Comprendre le fonctionnement d‚Äôun r√©seau de neurones multicouche (**MLP**).
- Manipuler les principaux **hyperparam√®tres** : nombre de neurones, couches, fonctions d‚Äôactivation, it√©rations.
- Observer les effets d‚Äô**underfitting**, d‚Äô**overfitting**, de **mauvaise convergence**.
- Relier ces ph√©nom√®nes au **compromis biais / variance**.
- D√©couvrir les notions cl√©s : **loss, convergence, solver, softmax, epochs/batchs, hyperparam√®tres**.
- Approfondir l‚Äôintuition de la **descente de gradient**.

Dur√©e cible : **2h √† 2h30**  
Plateforme recommand√©e : **Google Colab** (Python 3 + scikit-learn)

---

## √âtape 0 ‚Äî Pr√©paration et exploration des donn√©es

Nous allons travailler sur le dataset **Digits** de Scikit-learn.

üìö **Aide :** [Documentation officielle ‚Äì `load_digits`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html)

```python
from sklearn.datasets import load_digits
import matplotlib.pyplot as plt

digits = load_digits()
print("Taille du dataset :", digits.data.shape)
print("Nombre de classes :", len(digits.target_names))

# Visualisation rapide de quelques images
for i in range(4):
    plt.subplot(1,4,i+1)
    plt.imshow(digits.images[i], cmap='gray')
    plt.title(f"Label: {digits.target[i]}")
plt.show()
```

**Q1.** Qu'est ce que ce dataset ? Combien d‚Äôimages contient-il ? Quelle est la taille de chaque image ?  
**Q2.** Pourquoi les images doivent-elles √™tre **aplaties** (converties en 64 colonnes) avant d‚Äô√™tre utilis√©es par un MLP ?  
**Q3.** Combien de classes diff√©rentes contient ce jeu de donn√©es ?  

**Concept : `random_state`**
> Le param√®tre `random_state` fixe la graine al√©atoire pour rendre vos exp√©riences **reproductibles**.  
> Si vous l‚Äôenlevez, les r√©sultats peuvent l√©g√®rement varier d‚Äôune ex√©cution √† l‚Äôautre.  

**Q3bis.** Ex√©cutez deux fois le m√™me mod√®le avec et sans `random_state`. Que constatez-vous ?  

---

## √âtape 1 ‚Äî Cr√©er et entra√Æner un premier r√©seau simple

üìö **Aide :** [Documentation ‚Äì `MLPClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)

Nous allons cr√©er un r√©seau de neurones **avec une seule couche cach√©e** contenant 30 neurones.

```python
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay, classification_report

X_train, X_test, y_train, y_test = train_test_split(
    digits.data, digits.target, test_size=0.3, random_state=42, stratify=digits.target
)

# TODO : Compl√©tez les param√®tres du MLP
mlp = MLPClassifier(hidden_layer_sizes=(...), activation='...', max_iter=200, random_state=42)
mlp.fit(X_train, y_train)

# TODO : pr√©disez sur le jeu de test
y_pred = mlp.predict(...)

print("Accuracy (train):", mlp.score(..., ...))
print("Accuracy (test):", accuracy_score(..., ...))

ConfusionMatrixDisplay.from_estimator(mlp, X_test, y_test)
plt.show()
```

**Q4.** Quelle est la pr√©cision obtenue sur le jeu d‚Äôentra√Ænement et de test ?  
**Q5.** Que remarquez-vous dans la matrice de confusion ? Y a-t-il des chiffres plus difficiles √† reconna√Ætre ?  

---

### D√©couverte du rapport de classification

Scikit-learn fournit un r√©sum√© des performances appel√© **`classification_report`**, contenant plusieurs m√©triques :  

| Terme | Signification intuitive |
|-------|--------------------------|
| **precision** | parmi les exemples pr√©dits dans une classe, combien √©taient corrects ? |
| **recall (rappel)** | parmi les exemples r√©ellement dans cette classe, combien ont √©t√© bien trouv√©s ? |
| **f1-score** | moyenne harmonique pr√©cision/rappel ‚Äì √©quilibre entre les deux. |
| **support** | nombre d‚Äôexemples r√©els dans la classe. |

```python
from sklearn.metrics import classification_report
# TODO : affichez le rapport complet
print(classification_report(..., ...))
```

**Q5b.**  
1. Quelle diff√©rence voit-on entre **precision** et **recall** ?  
2. Pourquoi certaines classes ont-elles un **f1-score** plus bas que d‚Äôautres ?  
3. Que repr√©sente la colonne **support** ?  
4. Quelle m√©trique te semble la plus ‚Äújuste‚Äù globalement ?  

üìö **Aide :** [Documentation ‚Äì `classification_report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)

---

 **Sorties probabilistes ‚Äì Fonction Softmax**
> Le r√©seau ne ‚Äúdevine‚Äù pas une seule classe : il calcule une **probabilit√©** pour chaque chiffre possible (0‚Äì9).  
> Ces probabilit√©s sont normalis√©es par une fonction appel√©e **Softmax**, de sorte que leur somme = 1.

```python
# TODO : affichez les probabilit√©s de pr√©diction pour 5 chiffres
probas = mlp.predict_proba(X_test[:5])
print(probas)
```

**Q5c.** Pourquoi la somme de chaque ligne (probabilit√©s) vaut-elle toujours 1 ?  

---

## √âtape 2 ‚Äî Influence du nombre de neurones et de couches

Nous allons tester plusieurs architectures :  
- une seule couche cach√©e avec 20, 50 et 100 neurones ;  
- puis un r√©seau **√† deux couches** avec 50 et 20 neurones.

**Indice :** regardez le param√®tre `hidden_layer_sizes` dans la doc de `MLPClassifier`.

```python
hidden_layers = [(20,), (50,), (100,), (50,20)]
results = []

for hl in hidden_layers:
    # TODO : cr√©ez le mod√®le et entra√Ænez-le
    model = MLPClassifier(hidden_layer_sizes=hl, activation='relu', max_iter=300, random_state=42)
    model.fit(..., ...)
    acc_train = model.score(..., ...)
    acc_test = model.score(..., ...)
    results.append((hl, acc_train, acc_test))
    print(f"{str(hl):>10} -> train={acc_train:.3f}, test={acc_test:.3f}")
```

**Q7.** Quelle architecture donne les meilleurs r√©sultats sur le test ?  
**Q8.** Que se passe-t-il quand on augmente le nombre de neurones ?  
**Q9.** Le r√©seau √† deux couches fait-il toujours mieux ? Expliquez.  
**Q10.** Quel lien voyez-vous entre **taille du mod√®le** et **g√©n√©ralisation** ?  

 **Concept ‚Äì Hyperparam√®tres :**
> Les r√©glages choisis avant l‚Äôapprentissage (ex. nombre de couches, neurones, activation‚Ä¶) sont des **hyperparam√®tres**.  
> Le mod√®le apprend ensuite les **poids et biais** internes.  
> Plus tard, nous verrons comment automatiser le choix des hyperparam√®tres via la **validation crois√©e**.

---

## √âtape 3 ‚Äî Influence de la fonction d‚Äôactivation

Nous allons comparer trois fonctions d‚Äôactivation : `relu`, `tanh` et `logistic`.

**Aide :** [Documentation ‚Äì `MLPClassifier.activation`](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)

```python
activations = ['relu', 'tanh', 'logistic']

# TODO : compl√©tez la boucle pour entra√Æner et √©valuer chaque activation
for act in activations:
    model = MLPClassifier(hidden_layer_sizes=(50,20), activation=..., max_iter=300, random_state=42)
    model.fit(..., ...)
    print(f"Activation={act} -> train={model.score(..., ...):.3f}, test={model.score(..., ...):.3f}")
```

**Q11.** Quelle fonction d‚Äôactivation obtient les meilleurs r√©sultats ?  
**Q12.** Qu‚Äôobservez-vous sur la vitesse et la stabilit√© d‚Äôapprentissage ?  
**Q13.** Pourquoi `ReLU` est-elle souvent privil√©gi√©e dans les r√©seaux modernes ?  

---

## √âtape 4 ‚Äî Nombre d‚Äôit√©rations, convergence et descente de gradient

**Aide :** [Doc compl√®te ‚Äì Neural networks: training](https://scikit-learn.org/stable/modules/neural_networks_supervised.html)

Le param√®tre `max_iter` contr√¥le le nombre d‚Äô**it√©rations** du processus d‚Äôapprentissage (descente de gradient).  
Un message *"Maximum iterations reached and the optimization hasn't converged yet"* signifie que le mod√®le n‚Äôa pas compl√®tement converg√©.

**Concept ‚Äì Convergence :**  
> Un mod√®le ‚Äúconverge‚Äù lorsque la **loss (erreur)** ne diminue plus significativement.  
> Sinon, il faut plus d‚Äôit√©rations (`max_iter`) ou ajuster le **solver** (algorithme d‚Äôoptimisation).

**Concept ‚Äì Solver :**  
> Le param√®tre `solver` choisit la m√©thode d‚Äôoptimisation :  
> - `'adam'` (par d√©faut) : rapide et robuste.  
> - `'sgd'` : descente de gradient stochastique (plus bruit√©e).  
> - `'lbfgs'` : plus pr√©cis mais lent.  

**Concept ‚Äì Fonction de co√ªt (loss)**  
> La loss mesure l‚Äôerreur moyenne entre les pr√©dictions et les vraies classes.  
> Le r√©seau cherche √† la **minimiser**.  
> Par d√©faut, scikit-learn utilise la **log-loss (entropie crois√©e)**.  

**Concept ‚Äì Epoch et batch :**  
> - Une **epoch** = un passage complet sur les donn√©es d‚Äôentra√Ænement.  
> - L‚Äôapprentissage est souvent fait par ‚Äúbatches‚Äù (sous-parties du dataset).  
> - Chaque batch met √† jour les poids via la descente de gradient.  

```python
mlp_iter = MLPClassifier(hidden_layer_sizes=(50,20), activation='relu', max_iter=30, random_state=42)
mlp_iter.fit(X_train, y_train)

# TODO : tracez la courbe de la loss
plt.plot(...)
plt.title("Courbe de perte (loss) au fil des it√©rations")
plt.xlabel("It√©rations")
plt.ylabel("Loss")
plt.show()
```

**Q14.** Que repr√©sente la ‚Äúloss‚Äù sur cette courbe ?  
**Q14bis.** Pourquoi la loss ne descend-elle jamais sous z√©ro ? Quelle relation avec la pr√©cision (accuracy) ?  
**Q15.** Que se passe-t-il si vous augmentez `max_iter` √† 200 ou 500 ?  
**Q16.** Comment relier cela √† la **descente de gradient** vue en cours ?  
**Q16bis.** Que veut dire ‚Äúle mod√®le n‚Äôa pas converg√©‚Äù ? Comment le faire converger ?  
**Q16ter.** Essayez de changer `solver='sgd'` ‚Äì que remarquez-vous ?  
**Q17.** Pourquoi trop d‚Äôit√©rations peuvent-elles conduire √† un sur-apprentissage ?  
**Q17bis.** Si votre mod√®le converge mal, que pourriez-vous changer : `max_iter` ou la taille des batches ? Pourquoi ?  

---

## √âtape 5 ‚Äî Synth√®se et r√©flexion

**Q18.** R√©sumez ce que vous avez observ√© :  
- effet du nombre de neurones,  
- effet du nombre de couches,  
- effet de la fonction d‚Äôactivation,  
- effet du nombre d‚Äôit√©rations.  

**Q19.** Comment ces observations s‚Äôinscrivent-elles dans le compromis **biais / variance** ?  
**Q20.** Quelle combinaison d‚Äôhyperparam√®tres vous semble la plus √©quilibr√©e pour ce dataset ?  
**Q20bis.** Parmi tous les param√®tres du MLP, lesquels sont **appris** et lesquels sont **hyperparam√®tres** ?  

---

## Pour aller plus loin (optionnel)

1. **Tester un r√©seau plus profond :** ajoutez une 3e couche cach√©e `(100,50,20)` et observez.  
2. **Comparer avec un mod√®le plus simple :** testez une `LogisticRegression` sur le m√™me dataset.  
3. **Visualiser les erreurs :** affichez quelques chiffres mal class√©s.

```python
import numpy as np
misclassified = np.where(... != ...)[0][:4]
for idx in misclassified:
    plt.imshow(...[idx].reshape(8,8), cmap='gray')
    plt.title(f"Vrai: {...[idx]} / Pr√©dit: {...[idx]}")
    plt.show()
```
