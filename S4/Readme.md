# TP4 â€“ DÃ©couverte des rÃ©seaux de neurones convolutifs (CNN)

## Objectifs
- Comprendre la structure dâ€™un rÃ©seau convolutionnel (CNN)
- Comparer CNN et MLP sur des donnÃ©es dâ€™images (MNIST)
- Visualiser les filtres et cartes de caractÃ©ristiques (feature maps)
- Identifier les hyperparamÃ¨tres essentiels du CNN

DurÃ©e : 2hâ€“2h30  
Environnement : **Google Colab** (aucune installation nÃ©cessaire)

---

## Ã‰tape 0 â€“ Introduction : Keras vs PyTorch

### 0.1 Pourquoi ce choix ?

Il existe plusieurs bibliothÃ¨ques pour crÃ©er des rÃ©seaux de neurones :

| Framework | Niveau dâ€™abstraction | ParticularitÃ© |
|------------|---------------------|----------------|
| **Keras / TensorFlow** | Haut niveau | Simple, rapide Ã  utiliser, idÃ©al pour dÃ©buter |
| **PyTorch** | Plus bas niveau | Plus flexible, plus proche du fonctionnement interne |
| **Scikit-learn** | TrÃ¨s haut niveau | Pour modÃ¨les simples (KNN, MLP, etc.) |

Dans ce TP, nous utilisons **Keras (avec TensorFlow en arriÃ¨re-plan)** :  

**Q0.1.** Pourquoi Keras est-il plus adaptÃ© Ã  un premier TP sur les CNN ?  

**Q0.2.** Que changerait lâ€™utilisation de PyTorch ?  

---

## Ã‰tape 1 â€“ PrÃ©paration et exploration du dataset

### VÃ©rifions dâ€™abord notre environnement Colab :

```python
import tensorflow as tf
print("Version TensorFlow :", tf.__version__)
print("GPU disponible :", tf.config.list_physical_devices('GPU'))
```

> Si "GPU disponible : []", allez dans **ExÃ©cution â†’ Modifier le type dâ€™exÃ©cution â†’ AccÃ©lÃ©rateur matÃ©riel : GPU**.

**Q0.3.** Que change concrÃ¨tement lâ€™utilisation dâ€™un GPU par rapport au CPU lors de lâ€™entraÃ®nement ?  
ðŸ“š *Aide : [Keras â€“ GPU guide](https://www.tensorflow.org/guide/gpu)*  

---

### Chargement du dataset MNIST

```python
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt

(X_train, y_train), (X_test, y_test) = mnist.load_data()

print("Taille du dataset :", X_train.shape, X_test.shape)

# TODO : normaliser les pixels entre 0 et 1
# X_train = ...
# X_test = ...

# TODO : afficher 4 exemples du jeu d'entraÃ®nement avec plt.imshow()
```
ðŸ“š *Aide : [Keras MNIST Dataset](https://keras.io/api/datasets/mnist/)*  

**Q1.** Quelle est la taille dâ€™une image dâ€™entrÃ©e ?  
**Q2.** Pourquoi normaliser les pixels entre 0 et 1 ?  
**Q3.** Quelle est la dimension de sortie du modÃ¨le avant dâ€™ajouter le canal (28x28 -> ?)**  
**Q4.** Pourquoi doit-on â€œreshaperâ€ les donnÃ©es avant de les donner Ã  un CNN ?  

---

### Mise en forme pour le CNN

```python
# TODO : reshape les images pour ajouter le canal (28, 28, 1)
# TODO : encoder les labels (one-hot encoding)

# Exemple attendu :
# X_train = X_train.reshape(-1, 28, 28, 1)
# y_train_cat = to_categorical(y_train, 10)
```
ðŸ“š *Aide : [to_categorical â€“ Keras utils](https://keras.io/api/utils/python_utils/#to_categorical-function)*  

---

## Ã‰tape 2 â€“ ModÃ¨le MLP de rÃ©fÃ©rence

On commence par un MLP simple pour avoir un point de comparaison.

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten

mlp = Sequential([
    Flatten(input_shape=(28,28,1)),
    Dense(128, activation='relu'),
    Dense(10, activation='softmax')
])

mlp.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# TODO : entraÃ®ner le modÃ¨le sur 5 epochs
# history_mlp = mlp.fit(...)
```
ðŸ“š *Aide : [Sequential Model â€“ Keras](https://keras.io/api/models/sequential/)*  
ðŸ“š *Aide : [Model.fit() â€“ Keras](https://keras.io/api/models/model_training_apis/#fit-method)*  

**Q5.** Quelle prÃ©cision obtenez-vous sur le train et le test ?  
**Q6.** Pourquoi le MLP possÃ¨de-t-il beaucoup de paramÃ¨tres ?  
**Q7.** Quelles sont les limites du MLP pour des images ?  

---

## Ã‰tape 3 â€“ Construction dâ€™un petit CNN

CrÃ©ons un CNN simple Ã  2 couches convolutionnelles.

```python
from tensorflow.keras.layers import Conv2D, MaxPooling2D

cnn = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),
    MaxPooling2D((2,2)),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D((2,2)),
    Flatten(),
    Dense(64, activation='relu'),
    Dense(10, activation='softmax')
])

cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# TODO : entraÃ®ner le CNN sur 5 epochs, batch_size=128
# history_cnn = cnn.fit(...)
```
ðŸ“š *Aide : [Conv2D â€“ Keras](https://keras.io/api/layers/convolution_layers/convolution2d/)*  
ðŸ“š *Aide : [MaxPooling2D â€“ Keras](https://keras.io/api/layers/pooling_layers/max_pooling2d/)*  
ðŸ“š *Aide : [Flatten â€“ Keras](https://keras.io/api/layers/reshaping_layers/flatten/)*  

**Q8.** Combien de couches convolutives et de pooling contient ce rÃ©seau ?  
**Q9.** Pourquoi a-t-on besoin dâ€™une couche `Flatten()` avant les couches denses ?  
**Q10.** Quelle diffÃ©rence vois-tu entre ce modÃ¨le et le MLP prÃ©cÃ©dent ?  
**Q11.** Compare la prÃ©cision obtenue avec le CNN et le MLP.  

---

## Ã‰tape 4 â€“ Visualisation des performances

### Tracer les courbes dâ€™apprentissage

```python
import matplotlib.pyplot as plt

# TODO : tracer la prÃ©cision du train et du test pour le CNN
plt.plot(..., label='train')
plt.plot(..., label='test')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Ã‰volution de la prÃ©cision du CNN')
plt.legend()
plt.show()
```
ðŸ“š *Aide : [Model.fit() history object â€“ Keras](https://keras.io/api/models/model_training_apis/#fit-method)*  

**Q12.** Comment Ã©volue la prÃ©cision sur le train et le test ?  
**Q13.** Vois-tu un signe dâ€™overfitting ? (indices : Ã©cart entre train et test)  
**Q14.** Quelles solutions pourrais-tu proposer pour le limiter ? (Dropout, Data Augmentation, etc.)  

---

## Ã‰tape 5 â€“ Exploration visuelle : filtres et feature maps

### Afficher les filtres appris dans la premiÃ¨re couche
```python
weights, biases = cnn.layers[0].get_weights()
print("Forme des filtres :", weights.shape)
```
ðŸ“š *Aide : [get_weights() â€“ Keras](https://keras.io/api/models/model_training_apis/#get_weights-method)*  

### Visualiser les cartes de caractÃ©ristiques (feature maps)
```python
from tensorflow.keras import Model

# TODO : choisir une image test
sample = X_test[0].reshape(1,28,28,1)

# TODO : crÃ©er un modÃ¨le qui sort la premiÃ¨re couche convolutionnelle
model_layer1 = Model(inputs=cnn.inputs, outputs=cnn.layers[0].output)

feature_maps = model_layer1.predict(sample)

# TODO : afficher les 6 premiÃ¨res cartes
for i in range(6):
    plt.subplot(1,6,i+1)
    plt.imshow(feature_maps[0,:,:,i], cmap='gray')
    plt.axis('off')
plt.show()
```
ðŸ“š *Aide : [Functional API â€“ Model() Keras](https://keras.io/guides/functional_api/)*  

**Q15.** Que reprÃ©sentent les â€œpoidsâ€ de la premiÃ¨re couche ?  
**Q16.** Que montrent les â€œfeature mapsâ€ ?  
**Q17.** Les filtres apprennent-ils tous la mÃªme chose ? Pourquoi ?  

---

## Ã‰tape 6 â€“ Comparaison CNN vs MLP

| Aspect | MLP | CNN |
|---------|-----|-----|
| EntrÃ©e | ... | ... |
| Poids | ... | ... |
| Structure | ... | ... |
| PrÃ©cision | ... | ... |
| Robustesse | ... | ... |

**Q18.** Pourquoi le CNN gÃ©nÃ©ralise-t-il mieux que le MLP ?  
**Q19.** Que se passerait-il si on ajoutait plus de couches convolutionnelles ?  
**Q20.** Dans quels cas un MLP resterait-il plus adaptÃ© quâ€™un CNN ?  

---

## Bonus : aller plus loin

1. Ajoute une couche **Dropout(0.25)** aprÃ¨s le Flatten.  
2. Relance lâ€™entraÃ®nement et observe lâ€™effet sur la prÃ©cision.  
3. Essaie un **filtre 5Ã—5** au lieu de 3Ã—3.  
4. Compare le nombre de paramÃ¨tres entre MLP et CNN :  
   ```python
   cnn.summary()
   mlp.summary()
   ```
ðŸ“š *Aide : [Dropout â€“ Keras layer](https://keras.io/api/layers/regularization_layers/dropout/)*  

**Q21.** Que remarques-tu sur la complexitÃ© des modÃ¨les ?  
**Q22.** Quel est le lien entre nombre de paramÃ¨tres et risque dâ€™overfitting ?  

---

## SynthÃ¨se

Ce TP vous a permis de :
- Construire un **CNN** avec Keras.
- Comprendre la diffÃ©rence entre **MLP** et **CNN**.
- Visualiser ce que le rÃ©seau apprend rÃ©ellement (feature maps).
- Relier les **hyperparamÃ¨tres** Ã  la performance et Ã  la gÃ©nÃ©ralisation.

**Message clÃ© :**
> Un CNN nâ€™a pas besoin quâ€™on lui dise â€œce quâ€™est un bordâ€ :  
> il lâ€™apprend automatiquement Ã  travers ses filtres.
