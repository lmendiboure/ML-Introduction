# TP ‚Äì S√©ance 1 : Premiers pas en Machine Learning

## üéØ Objectifs
- Explorer un vrai dataset et comprendre sa structure.
- D√©couvrir un premier algorithme : **k plus proches voisins (k-NN)**.
- √âvaluer un mod√®le avec **accuracy** et **matrice de confusion**.
- Comparer avec un autre mod√®le simple : **r√©gression logistique**.
- Apprendre √† tester et analyser diff√©rents param√®tres.

‚è≥ Dur√©e : environ **2h**  
üìç Outil : **Google Colab**

---

## √âtape 0 ‚Äì Pr√©parer l‚Äôenvironnement
Copiez-collez le code ci-dessous dans un nouveau notebook Google Colab :

```python
import pandas as pd
import numpy as np
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score
```

**Q1.** √Ä votre avis, pourquoi importer autant de biblioth√®ques diff√©rentes ?  
üëâ Astuce : cherchez rapidement chaque module sur [scikit-learn.org](https://scikit-learn.org/stable/).

---

## √âtape 1 ‚Äì Explorer le dataset
```python
data = load_breast_cancer()
X = data.data
y = data.target
```

- Affichez la **taille** de `X` (`.shape`).  
- Affichez les **noms des variables** (`data.feature_names`).  
- Affichez les **classes cibles** (`data.target_names`).  

**Q2.** Combien d‚Äôexemples (lignes) et combien de variables (colonnes) contient le dataset ?  
**Q3.** Que repr√©sente une **ligne** dans X ?  
**Q4.** Quelles sont les deux classes √† pr√©dire (y=0 et y=1) ?

---

## √âtape 2 ‚Äì D√©couper en apprentissage et test
```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)
```

**Q5.** Quelle proportion de donn√©es est r√©serv√©e au test ?  
**Q6.** Pourquoi est-il important de s√©parer apprentissage et test ?  
**Q7.** Que se passerait-il si on utilisait le m√™me jeu pour apprendre et tester ?

---

## √âtape 3 ‚Äì Premier mod√®le : k-NN
```python
knn = Pipeline([
    ('scaler', StandardScaler()),
    ('clf', KNeighborsClassifier(n_neighbors=5))
])
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)
```

**Q8.** Pourquoi ajoute-t-on un `StandardScaler` avant le classifieur ?  
**Q9.** Expliquez avec vos mots la diff√©rence entre `.fit()` et `.predict()`.  
**Q10.** Que signifie `n_neighbors=5` ? Que changerait k=1 ou k=20 ?

---

## √âtape 4 ‚Äì √âvaluer le mod√®le
```python
print("Accuracy k-NN:", accuracy_score(y_test, y_pred_knn))
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_knn)
```

**Q11.** Quelle est l‚Äôaccuracy obtenue ?  
**Q12.** Dans la matrice de confusion, que repr√©sentent les 4 cases ?  
**Q13.** Pourquoi la matrice de confusion donne plus d‚Äôinformations que l‚Äôaccuracy seule ?

---

## √âtape 5 ‚Äì Tester plusieurs valeurs de k
```python
scores = []
for k in [1, 3, 5, 7, 9, 11]:
    knn = Pipeline([
        ('scaler', StandardScaler()),
        ('clf', KNeighborsClassifier(n_neighbors=k))
    ])
    knn.fit(X_train, y_train)
    acc = knn.score(X_test, y_test)
    scores.append((k, acc))
    print(f"k={k}, accuracy={acc:.3f}")
```

**Q14.** Quelle valeur de k donne la meilleure accuracy ?  
**Q15.** Expliquez pourquoi un k trop petit ou trop grand peut poser probl√®me.  
**Q16.** Tracez un graphique (k vs accuracy). Qu‚Äôobservez-vous ?

---

## √âtape 6 ‚Äì Comparer avec la r√©gression logistique
```python
log_reg = Pipeline([
    ('scaler', StandardScaler()),
    ('clf', LogisticRegression(max_iter=500))
])
log_reg.fit(X_train, y_train)
y_pred_log = log_reg.predict(X_test)

print("Accuracy Logistique:", accuracy_score(y_test, y_pred_log))
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_log)
```

**Q17.** Quelle est l‚Äôaccuracy de la r√©gression logistique ?  
**Q18.** Entre k-NN et logistique, quel mod√®le fonctionne le mieux sur ce dataset ?

---

## √âtape 7 ‚Äì Mini-d√©fi üéØ
- Essayez d‚Äôobtenir une **accuracy > 0.95**.  
- Pour cela, vous pouvez :  
  - modifier la valeur de k,  
  - changer les param√®tres de `LogisticRegression` (par ex. `penalty`, `C`),  
  - ou explorer d‚Äôautres classifieurs (`DecisionTreeClassifier` par exemple).  

**Q19.** Quel est votre meilleur mod√®le ? Quelle est son accuracy ?  
**Q20.** Quelle serait la prochaine √©tape pour aller plus loin (indices : validation crois√©e, autres m√©triques, etc.) ?

---
