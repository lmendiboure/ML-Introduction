# TP ‚Äì S√©ance 1 

## Premiers pas en apprentissage supervis√© avec scikit-learn

### Objectifs
- Explorer un **vrai dataset** (Breast Cancer) et comprendre sa structure (lignes, colonnes, classes).  
- Identifier le **type de t√¢che** et le **type d‚Äôapprentissage** correspondant.  
- D√©couvrir deux algorithmes supervis√©s : **k plus proches voisins (k-NN)** et **r√©gression logistique**.  
- √âvaluer un mod√®le avec l‚Äô**accuracy** et la **matrice de confusion**.  
- Tester et justifier des choix de param√®tres (valeurs de *k*, normalisation, hyperparam√®tres).  

üõ†Ô∏è Plateforme : **Google Colab** ou Python 3 + scikit-learn.  

---

## Rep√®res utiles (o√π chercher l‚Äôinfo)
- Guide de d√©marrage : https://scikit-learn.org/stable/getting_started.html  
- `KNeighborsClassifier` : https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html  
- `LogisticRegression` : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html  
- `Pipeline` : https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html  
- `StandardScaler` : https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html  
- `train_test_split` : https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html  
- `ConfusionMatrixDisplay` : https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html  

Astuce Colab : affichez l‚Äôaide courte d‚Äôune classe avec `KNeighborsClassifier?`.

---

## √âtape 0 ‚Äî Pr√©parer l‚Äôenvironnement
```python
import numpy as np, pandas as pd
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
```

**Q1.** √Ä quoi sert `Pipeline` dans un flux de travail ML ?  
**Q2.** √Ä quoi sert `StandardScaler` ?  
**Q3.** Pourquoi a-t-on besoin √† la fois de modules pour les donn√©es (`train_test_split`, `StandardScaler`) et pour les mod√®les (`KNeighborsClassifier`, `LogisticRegression`) ?  

---

## √âtape 1 ‚Äî Explorer le dataset
```python
data = load_breast_cancer()
X, y = data.data, data.target
feature_names, target_names = data.feature_names, data.target_names

print("X shape:", X.shape)
print("y shape:", y.shape)
print("Features (10 premi√®res):", feature_names[:10])
print("Classes:", target_names)

pd.DataFrame(X, columns=feature_names).head()
```

**Q4.** Combien y a-t-il d‚Äôexemples (lignes) et de variables (colonnes) ?  
**Q5.** Que repr√©sente une **ligne** dans `X` ?  
**Q6.** Que signifient les classes `target_names` ? Qui est 0, qui est 1 ?  
**Q7.** Est-ce un probl√®me de **classification** ou de **r√©gression** ? Justifiez votre r√©ponse.  

---

## √âtape 2 ‚Äî S√©parer apprentissage et test
```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.30, random_state=42, stratify=y
)
print(X_train.shape, X_test.shape)
```

**Q8.** Quelle proportion est r√©serv√©e au test ?  
**Q9.** Pourquoi ne pas tout utiliser pour l‚Äôapprentissage **et** le test ?  
**Q10.** √Ä quoi sert `stratify=y` ?  

---

## √âtape 3 ‚Äî Construire un premier mod√®le k-NN (avec normalisation)
Compl√©tez :

```python
knn = Pipeline(steps=[
    ('scaler', StandardScaler()),          
    ('clf', KNeighborsClassifier(n_neighbors=...))  # choisir k
])

knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)
acc_knn = knn.score(X_test, y_test)
print(f"Accuracy k-NN (k=?): {acc_knn:.3f}")
```

**Q11.** Pourquoi standardiser les features avant k-NN ?  
**Q12.** Expliquez avec vos mots ce que font `fit()` et `predict()`.  
**Q13.** D‚Äôapr√®s le nom ‚Äúk plus proches voisins‚Äù, comment le mod√®le prend-il une d√©cision ?  

---

## √âtape 4 ‚Äî Lire une matrice de confusion
```python
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_knn)
plt.show()
```

**Q14.** Que repr√©sentent les 4 cases de la matrice ? 
**Q15.** Pourquoi la matrice de confusion donne plus d‚Äôinformations que l‚Äôaccuracy seule ?  

---

## √âtape 5 ‚Äî Choisir k de mani√®re raisonn√©e
```python
n_train = len(X_train)
k_max = int(np.ceil(np.sqrt(n_train)))
print("Taille train:", n_train, "‚Üí k_max recommand√© ‚âà", k_max)

# TODO : g√©n√©rez une liste de valeurs impaires entre 1 et k_max inclus
k_values = [ ... ]
```

**Q16.** Quelle m√©thode utilisez-vous pour obtenir uniquement des valeurs **impaires** ?  
**Q17.** Pourquoi tester plusieurs k est-il n√©cessaire ?  

---

## √âtape 6 ‚Äî √âvaluer plusieurs k
Compl√©tez :

```python
results = []
for k in k_values:
    model = Pipeline(steps=[
        ('scaler', StandardScaler()),
        ('clf', KNeighborsClassifier(n_neighbors=k))
    ])
    model.fit(X_train, y_train)
    acc = model.score(X_test, y_test)
    results.append((k, acc))

print(results[:10])
```

**Q18.** Quel est le **meilleur k** trouv√© ? Quelle est son accuracy ?  
**Q19.** En comparant petits et grands k, que remarquez-vous (sensibilit√© au bruit vs g√©n√©ralisation) ?  

---

## √âtape 7 ‚Äî Comparer avec la r√©gression logistique
```python
log_reg = Pipeline(steps=[
    ('scaler', StandardScaler()),
    ('clf', LogisticRegression(max_iter=500))
])
log_reg.fit(X_train, y_train)
y_pred_log = log_reg.predict(X_test)
acc_log = log_reg.score(X_test, y_test)
print(f"Accuracy Logistique: {acc_log:.3f}")

ConfusionMatrixDisplay.from_predictions(y_test, y_pred_log)
plt.show()
```

**Q20.** Quelle est l‚Äôaccuracy de la r√©gression logistique ?  
**Q21.** Lequel est meilleur : votre meilleur k-NN ou la logistique ?  
**Q22.** Selon vous, la r√©gression logistique renvoie-t-elle une probabilit√© ou directement une classe ? Justifiez.  

---

## √âtape 8 ‚Äî Effet de la normalisation
```python
knn_no_scaler = Pipeline(steps=[
    ('clf', KNeighborsClassifier(n_neighbors=...))  # reprenez votre meilleur k
])
knn_no_scaler.fit(X_train, y_train)
print("Accuracy k-NN sans scaler:", knn_no_scaler.score(X_test, y_test))
```

**Q23.** Quelle diff√©rence observez-vous en retirant la normalisation ?  
**Q24.** Que concluez-vous sur l‚Äôimportance du `StandardScaler` ?  

---

## √âtape 9 ‚Äî Mini-d√©fi (Maximiser l'accuracy)
- Ajustez *k* ou les param√®tres de la logistique (`C`, `penalty`).  
- Visez le maximum d‚Äôaccuracy.  

**Q25.** Quel est votre meilleur mod√®le ? Donnez ses param√®tres et son accuracy.  
**Q26.** Comment appelle-t-on le processus consistant √† ajuster de tels param√®tres ?

---

## √âtape 10 ‚Äî Limites de l‚Äôaccuracy et ouverture
**Q27.** Quelle est la limite de l‚Äôaccuracy comme seule m√©trique (pensez aux classes d√©s√©quilibr√©es ou au co√ªt des erreurs) ?  

---

## √Ä rendre
- Votre notebook avec code compl√©t√©.  
- R√©ponses aux questions Q1‚ÄìQ27.  
- Figures (matrices, courbe k vs accuracy).

## Bonus 1 ‚Äî Courbes d‚Äôapprentissage

Nous voulons voir comment l‚Äôaccuracy √©volue quand on augmente la taille du jeu d‚Äôentra√Ænement.

```python
from sklearn.model_selection import learning_curve

train_sizes, train_scores, test_scores = learning_curve(
    LogisticRegression(max_iter=500),
    X, y, cv=5, train_sizes=np.linspace(0.1, 1.0, 5)
)

import matplotlib.pyplot as plt
plt.plot(train_sizes, train_scores.mean(axis=1), label="train")
plt.plot(train_sizes, test_scores.mean(axis=1), label="test")
plt.legend()
plt.show()
```

**QB1**. Que remarquez-vous lorsque la taille du jeu de train augmente ?
**QB2.** Comment interpr√©ter un √©cart entre courbe train et test ? (indice : underfit vs overfit).

## Bonus 2 ‚Äî Autres m√©triques que l‚Äôaccuracy

```python
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred_knn))
```

**QB3.** Que signifient pr√©cision (precision), rappel (recall) et F1-score ?
**QB4.** Pourquoi l‚Äôaccuracy seule peut √™tre trompeuse si les classes sont tr√®s d√©s√©quilibr√©es ?

## Bonus 3 ‚Äî Visualiser la fronti√®re de d√©cision (2 features)

R√©duisons le dataset √† 2 variables pour mieux visualiser.

```python
X2 = X[:, :2]   # prenons les 2 premi√®res features
X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y, test_size=0.3, random_state=42)

knn2 = KNeighborsClassifier(n_neighbors=5)
knn2.fit(X2_train, y2_train)

# Code de visualisation √† compl√©ter (scatter + contourf)
```

**QB5.** Dessinez la fronti√®re de d√©cision pour k-NN avec 2 features.
**QB6.** Faites de m√™me pour la logistique. Quelle diff√©rence visuelle observez-vous entre les deux mod√®les ?
