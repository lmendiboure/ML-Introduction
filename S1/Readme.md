# TP â€“ SÃ©ance 1 

## Premiers pas en apprentissage supervisÃ© avec scikit-learn

### Objectifs
- Explorer un **vrai dataset** (Breast Cancer) et comprendre sa structure (lignes, colonnes, classes).  
- Identifier le **type de tÃ¢che** et le **type dâ€™apprentissage** correspondant.  
- DÃ©couvrir deux algorithmes supervisÃ©s : **k plus proches voisins (k-NN)** et **rÃ©gression logistique**.  
- Ã‰valuer un modÃ¨le avec lâ€™**accuracy** et la **matrice de confusion**.  
- Tester et justifier des choix de paramÃ¨tres (valeurs de *k*, normalisation, hyperparamÃ¨tres).  

ğŸ› ï¸ Plateforme : **Google Colab** ou Python 3 + scikit-learn.  

---

## RepÃ¨res utiles (oÃ¹ chercher lâ€™info)
- Guide de dÃ©marrage : https://scikit-learn.org/stable/getting_started.html  
- `KNeighborsClassifier` : https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html  
- `LogisticRegression` : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html  
- `Pipeline` : https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html  
- `StandardScaler` : https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html  
- `train_test_split` : https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html  
- `ConfusionMatrixDisplay` : https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html  

Astuce Colab : affichez lâ€™aide courte dâ€™une classe avec `KNeighborsClassifier?`.

---

## Ã‰tape 0 â€” PrÃ©parer lâ€™environnement
```python
import numpy as np, pandas as pd
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
```

**Q1.** Ã€ quoi sert `Pipeline` dans un flux de travail ML ?  
**Q2.** Ã€ quoi sert `StandardScaler` ?  
**Q3.** Pourquoi a-t-on besoin Ã  la fois de modules pour les donnÃ©es (`train_test_split`, `StandardScaler`) et pour les modÃ¨les (`KNeighborsClassifier`, `LogisticRegression`) ?  

---

## Ã‰tape 1 â€” Explorer le dataset
```python
data = load_breast_cancer()
X, y = data.data, data.target
feature_names, target_names = data.feature_names, data.target_names

print("X shape:", X.shape)
print("y shape:", y.shape)
print("Features (10 premiÃ¨res):", feature_names[:10])
print("Classes:", target_names)

pd.DataFrame(X, columns=feature_names).head()
```

**Q4.** Combien y a-t-il dâ€™exemples (lignes) et de variables (colonnes) ?  
**Q5.** Que reprÃ©sente une **ligne** dans `X` ?  
**Q6.** Que signifient les classes `target_names` ? Qui est 0, qui est 1 ?  
**Q7.** Est-ce un problÃ¨me de **classification** ou de **rÃ©gression** ? Justifiez votre rÃ©ponse.  

---

## Ã‰tape 2 â€” SÃ©parer apprentissage et test
```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.30, random_state=42, stratify=y
)
print(X_train.shape, X_test.shape)
```

**Q8.** Quelle proportion est rÃ©servÃ©e au test ?  
**Q9.** Pourquoi ne pas tout utiliser pour lâ€™apprentissage **et** le test ?  
**Q10.** Ã€ quoi sert `stratify=y` ?  

---

## Ã‰tape 3 â€” Construire un premier modÃ¨le k-NN (avec normalisation)
ComplÃ©tez :

```python
knn = Pipeline(steps=[
    ('scaler', StandardScaler()),          
    ('clf', KNeighborsClassifier(n_neighbors=...))  # choisir k
])

knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)
acc_knn = knn.score(X_test, y_test)
print(f"Accuracy k-NN (k=?): {acc_knn:.3f}")
```

**Q11.** Pourquoi standardiser les features avant k-NN ?  
**Q12.** Expliquez avec vos mots ce que font `fit()` et `predict()`.  
**Q13.** Dâ€™aprÃ¨s le nom â€œk plus proches voisinsâ€, comment le modÃ¨le prend-il une dÃ©cision ?  

---

## Ã‰tape 4 â€” Lire une matrice de confusion
```python
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_knn)
plt.show()
```

**Q14.** Que reprÃ©sentent les 4 cases de la matrice ? 
**Q15.** Pourquoi la matrice de confusion donne plus dâ€™informations que lâ€™accuracy seule ?  

---

## Ã‰tape 5 â€” Choisir k de maniÃ¨re raisonnÃ©e
```python
n_train = len(X_train)
k_max = int(np.ceil(np.sqrt(n_train)))
print("Taille train:", n_train, "â†’ k_max recommandÃ© â‰ˆ", k_max)

# TODO : gÃ©nÃ©rez une liste de valeurs impaires entre 1 et k_max inclus
k_values = [ ... ]
```

**Q16.** Quelle mÃ©thode utilisez-vous pour obtenir uniquement des valeurs **impaires** ?  
**Q17.** Pourquoi tester plusieurs k est-il nÃ©cessaire ?  

---

## Ã‰tape 6 â€” Ã‰valuer plusieurs k
ComplÃ©tez :

```python
results = []
for k in k_values:
    model = Pipeline(steps=[
        ('scaler', StandardScaler()),
        ('clf', KNeighborsClassifier(n_neighbors=k))
    ])
    model.fit(X_train, y_train)
    acc = model.score(X_test, y_test)
    results.append((k, acc))

print(results[:10])
```

**Q18.** Quel est le **meilleur k** trouvÃ© ? Quelle est son accuracy ?  
**Q19.** En comparant petits et grands k, que remarquez-vous (sensibilitÃ© au bruit vs gÃ©nÃ©ralisation) ?  

---

## Ã‰tape 7 â€” Comparer avec la rÃ©gression logistique
```python
log_reg = Pipeline(steps=[
    ('scaler', StandardScaler()),
    ('clf', LogisticRegression(max_iter=500))
])
log_reg.fit(X_train, y_train)
y_pred_log = log_reg.predict(X_test)
acc_log = log_reg.score(X_test, y_test)
print(f"Accuracy Logistique: {acc_log:.3f}")

ConfusionMatrixDisplay.from_predictions(y_test, y_pred_log)
plt.show()
```

**Q20.** Quelle est lâ€™accuracy de la rÃ©gression logistique ?  
**Q21.** Lequel est meilleur : votre meilleur k-NN ou la logistique ?  
**Q22.** Selon vous, la rÃ©gression logistique renvoie-t-elle une probabilitÃ© ou directement une classe ? Justifiez.  

---

## Ã‰tape 8 â€” Effet de la normalisation
```python
knn_no_scaler = Pipeline(steps=[
    ('clf', KNeighborsClassifier(n_neighbors=...))  # reprenez votre meilleur k
])
knn_no_scaler.fit(X_train, y_train)
print("Accuracy k-NN sans scaler:", knn_no_scaler.score(X_test, y_test))
```

**Q23.** Quelle diffÃ©rence observez-vous en retirant la normalisation ?  
**Q24.** Que concluez-vous sur lâ€™importance du `StandardScaler` ?  

---

## Ã‰tape 9 â€” Mini-dÃ©fi (> 0.95 dâ€™accuracy)
- Ajustez *k* ou les paramÃ¨tres de la logistique (`C`, `penalty`).  
- Visez > 0.95 dâ€™accuracy.  

**Q25.** Quel est votre meilleur modÃ¨le ? Donnez ses paramÃ¨tres et son accuracy.  
**Q26.** Comment appelle-t-on le processus consistant Ã  ajuster de tels paramÃ¨tres ?

---

## Ã‰tape 10 â€” Limites de lâ€™accuracy et ouverture
**Q27.** Quelle est la limite de lâ€™accuracy comme seule mÃ©trique (pensez aux classes dÃ©sÃ©quilibrÃ©es ou au coÃ»t des erreurs) ?  

---

## Ã€ rendre
- Votre notebook avec code complÃ©tÃ©.  
- RÃ©ponses aux questions Q1â€“Q27.  
- Figures (matrices, courbe k vs accuracy).  
